{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение в обработку текста на естественном языке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Материалы:\n",
    "* Макрушин С.В. Лекция 9: Введение в обработку текста на естественном языке\\\n",
    "* https://realpython.com/nltk-nlp-python/\n",
    "* https://scikit-learn.org/stable/modules/feature_extraction.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задачи для совместного разбора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.metrics.distance import edit_distance\n",
    "import pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = 'ПИ19-1'\n",
    "s2 = 'ПИ19-1'\n",
    "edit_distance(s1, s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Считайте слова из файла `litw-win.txt` и запишите их в список `words`. В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка `words`. Считайте, что в слове есть опечатка, если данное слово не содержится в списке `words`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''с велечайшим усилием выбравшись из потока убегающих людей Кутузов со свитой уменьшевшейся вдвое поехал на звуки выстрелов русских орудий'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['высокопревосходительства',\n",
       " 'попреблагорассмотрительст',\n",
       " 'попреблагорассмотрительствующемуся',\n",
       " 'убегающих',\n",
       " 'уменьшившейся']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = []\n",
    "with open('./data/litw-win.txt') as fp:\n",
    "    for line in fp:\n",
    "        words.append(line.strip().split()[-1])\n",
    "        \n",
    "words[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'величайшим'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = 'велечайшим'\n",
    "min(words, key=lambda k: edit_distance(word, k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Разбейте текст из формулировки задания 1 на слова; проведите стемминг и лемматизацию слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'попреблагорассмотрительств'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = SnowballStemmer('russian')\n",
    "stemmer.stem('попреблагорассмотрительствующемуся')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'попреблагорассмотрительствующийся'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "morph.parse('попреблагорассмотрительствующемуся')[0].normalized.word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Преобразуйте предложения из формулировки задания 1 в векторы при помощи `CountVectorizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Считайте слова из файла `litw-win.txt` и запишите их в список `words`.',\n",
       " 'В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка `words`.',\n",
       " 'Считайте, что в слове есть опечатка, если данное слово не содержится в списке `words`.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '''Считайте слова из файла `litw-win.txt` и запишите их в список `words`. В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка `words`. Считайте, что в слове есть опечатка, если данное слово не содержится в списке `words`. '''\n",
    "sents = sent_tokenize(text)\n",
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0],\n",
       "       [0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 2, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "        0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '''Считайте слова из файла `litw-win.txt` и запишите их в список `words`. В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка `words`. Считайте, что в слове есть опечатка, если данное слово не содержится в списке `words`. '''\n",
    "sents = sent_tokenize(text)\n",
    "sents\n",
    "cv = CountVectorizer()\n",
    "cv.fit(sents)\n",
    "sents_cv = cv.transform(sents).toarray()\n",
    "sents_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0],\n",
       "       [0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 2, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "        0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents_cv = cv.transform(sents).toarray()\n",
    "sents_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 35)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'считайте': 32,\n",
       " 'слова': 24,\n",
       " 'из': 12,\n",
       " 'файла': 33,\n",
       " 'litw': 0,\n",
       " 'win': 2,\n",
       " 'txt': 1,\n",
       " 'запишите': 11,\n",
       " 'их': 14,\n",
       " 'список': 31,\n",
       " 'words': 3,\n",
       " 'заданном': 9,\n",
       " 'предложении': 22,\n",
       " 'исправьте': 13,\n",
       " 'все': 5,\n",
       " 'опечатки': 21,\n",
       " 'заменив': 10,\n",
       " 'опечатками': 20,\n",
       " 'на': 16,\n",
       " 'ближайшие': 4,\n",
       " 'смысле': 27,\n",
       " 'расстояния': 23,\n",
       " 'левенштейна': 15,\n",
       " 'ним': 18,\n",
       " 'списка': 29,\n",
       " 'что': 34,\n",
       " 'слове': 25,\n",
       " 'есть': 8,\n",
       " 'опечатка': 19,\n",
       " 'если': 7,\n",
       " 'данное': 6,\n",
       " 'слово': 26,\n",
       " 'не': 17,\n",
       " 'содержится': 28,\n",
       " 'списке': 30}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лабораторная работа 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Расстояние редактирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import sent_tokenize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Загрузите предобработанные описания рецептов из файла `preprocessed_descriptions.csv`. Получите набор уникальных слов `words`, содержащихся в текстах описаний рецептов (воспользуйтесь `word_tokenize` из `nltk`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_descriptions = pd.read_csv('../sem08/result/preprocessed_descriptions.csv', index_col=0)\n",
    "preprocessed_descriptions['words'] = preprocessed_descriptions.apply(\n",
    "         lambda row: nltk.word_tokenize(str(row.preprocessed_description)),\n",
    "         axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # v2\n",
    "# preprocessed_descriptions['FreqDist'] = preprocessed_descriptions.apply(\n",
    "#          lambda row: nltk.FreqDist(row.words),\n",
    "#          axis=1)\n",
    "# dicti = {}\n",
    "# unique = preprocessed_descriptions.apply(\n",
    "#          lambda row: dicti.update(row.FreqDist),\n",
    "#          axis=1)\n",
    "# words = list(dicti.keys())\n",
    "# words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dc',\n",
       " 'sharingvegeta',\n",
       " 'humor',\n",
       " 'aborio',\n",
       " 'higher',\n",
       " 'indimidate',\n",
       " 'destroy',\n",
       " 'saucing',\n",
       " 'apptiteverynight',\n",
       " 'collect',\n",
       " 'guest',\n",
       " 'least',\n",
       " 'widemouth',\n",
       " 'goer',\n",
       " 'crunchies']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = list(set(np.hstack(preprocessed_descriptions['words'].to_list())))\n",
    "words[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Сгенерируйте 5 пар случайно выбранных слов и посчитайте между ними расстояние редактирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from nltk.metrics.distance import edit_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ladida', 'smokehouse'),\n",
       " ('antinori', 'ste'),\n",
       " ('noninstant', 'legally'),\n",
       " ('reminded', 'sunchokes'),\n",
       " ('jewel', 'brekky')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choices = list(zip(random.choices(words, k=5),random.choices(words, k=5)))\n",
    "choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ladida, smokehouse => расстояние: 10\n",
      "antinori, ste => расстояние: 7\n",
      "noninstant, legally => расстояние: 10\n",
      "reminded, sunchokes => расстояние: 8\n",
      "jewel, brekky => расстояние: 5\n"
     ]
    }
   ],
   "source": [
    "distance = [edit_distance(words[0], words[1]) for words in choices]\n",
    "for idx, el in enumerate(distance):\n",
    "    print(f'{choices[idx][0]}, {choices[idx][1]} => расстояние: {el}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 Напишите функцию, которая для заданного слова `word` возвращает `k` ближайших к нему слов из списка `words` (близость слов измеряется с помощью расстояния Левенштейна)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_distance(word, k):\n",
    "    word_dist_dict = {}\n",
    "    for el in words:\n",
    "        word_dist_dict[el] = edit_distance(word, el)\n",
    "    lst = [k for k,v in sorted(word_dist_dict.items(), key=lambda item: item[1])[:k]]\n",
    "    return lst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['promising',\n",
       " 'premixing',\n",
       " 'promoting',\n",
       " 'providing',\n",
       " 'roiling',\n",
       " 'producing',\n",
       " 'revising']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 7 #рандомно\n",
    "find_distance('promising', k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стемминг, лемматизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 На основе результатов 1.1 создайте `pd.DataFrame` со столбцами: \n",
    "    * word\n",
    "    * stemmed_word \n",
    "    * normalized_word \n",
    "\n",
    "Столбец `word` укажите в качестве индекса. \n",
    "\n",
    "Для стемминга воспользуйтесь `SnowballStemmer`, для нормализации слов - `WordNetLemmatizer`. Сравните результаты стемминга и лемматизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_normilized_words = pd.DataFrame(words, columns=['word'])\n",
    "\n",
    "stemmed_normilized_words['stemmed_word'] = stemmed_normilized_words.apply(\n",
    "         lambda row: stemmer.stem(row.word),\n",
    "         axis=1)\n",
    "stemmed_normilized_words['normalized_word'] = stemmed_normilized_words.apply(\n",
    "         lambda row: lemmatizer.lemmatize(row.word),\n",
    "         axis=1)\n",
    "\n",
    "stemmed_normilized_words.set_index('word', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stemmed_word</th>\n",
       "      <th>normalized_word</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>indimidate</th>\n",
       "      <td>indimid</td>\n",
       "      <td>indimidate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>destroy</th>\n",
       "      <td>destroy</td>\n",
       "      <td>destroy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saucing</th>\n",
       "      <td>sauc</td>\n",
       "      <td>saucing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apptiteverynight</th>\n",
       "      <td>apptiteverynight</td>\n",
       "      <td>apptiteverynight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collect</th>\n",
       "      <td>collect</td>\n",
       "      <td>collect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guest</th>\n",
       "      <td>guest</td>\n",
       "      <td>guest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>least</th>\n",
       "      <td>least</td>\n",
       "      <td>least</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>widemouth</th>\n",
       "      <td>widemouth</td>\n",
       "      <td>widemouth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>goer</th>\n",
       "      <td>goer</td>\n",
       "      <td>goer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crunchies</th>\n",
       "      <td>crunchi</td>\n",
       "      <td>crunchies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oz182wt</th>\n",
       "      <td>oz182wt</td>\n",
       "      <td>oz182wt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>basisit</th>\n",
       "      <td>basisit</td>\n",
       "      <td>basisit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alternatively</th>\n",
       "      <td>altern</td>\n",
       "      <td>alternatively</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1921</th>\n",
       "      <td>1921</td>\n",
       "      <td>1921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>garliclovers</th>\n",
       "      <td>garliclov</td>\n",
       "      <td>garliclovers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scarbroughs</th>\n",
       "      <td>scarbrough</td>\n",
       "      <td>scarbroughs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buddha</th>\n",
       "      <td>buddha</td>\n",
       "      <td>buddha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coarses</th>\n",
       "      <td>coars</td>\n",
       "      <td>coarses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>please</th>\n",
       "      <td>pleas</td>\n",
       "      <td>please</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13675</th>\n",
       "      <td>13675</td>\n",
       "      <td>13675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preston</th>\n",
       "      <td>preston</td>\n",
       "      <td>preston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chain</th>\n",
       "      <td>chain</td>\n",
       "      <td>chain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cassel</th>\n",
       "      <td>cassel</td>\n",
       "      <td>cassel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breastveal</th>\n",
       "      <td>breastveal</td>\n",
       "      <td>breastveal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pails</th>\n",
       "      <td>pail</td>\n",
       "      <td>pail</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      stemmed_word   normalized_word\n",
       "word                                                \n",
       "indimidate                 indimid        indimidate\n",
       "destroy                    destroy           destroy\n",
       "saucing                       sauc           saucing\n",
       "apptiteverynight  apptiteverynight  apptiteverynight\n",
       "collect                    collect           collect\n",
       "guest                        guest             guest\n",
       "least                        least             least\n",
       "widemouth                widemouth         widemouth\n",
       "goer                          goer              goer\n",
       "crunchies                  crunchi         crunchies\n",
       "oz182wt                    oz182wt           oz182wt\n",
       "basisit                    basisit           basisit\n",
       "alternatively               altern     alternatively\n",
       "1921                          1921              1921\n",
       "garliclovers             garliclov      garliclovers\n",
       "scarbroughs             scarbrough       scarbroughs\n",
       "buddha                      buddha            buddha\n",
       "coarses                      coars           coarses\n",
       "please                       pleas            please\n",
       "13675                        13675             13675\n",
       "preston                    preston           preston\n",
       "chain                        chain             chain\n",
       "cassel                      cassel            cassel\n",
       "breastveal              breastveal        breastveal\n",
       "pails                         pail              pail"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_normilized_words[5:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*\n",
    "\n",
    "**объяснение**\n",
    "\n",
    "\n",
    "Лемматизация правильно определила базовую форму (\"please\"), в то время как стемминг отрезал «e» и преобразовал ее в \"pleas\".\n",
    "Но в некоторых случаях для лемматизации важно часть знать речи, т.к. в английском языке одинковые слова могут быть разными частями речи в зависимости от смысла, а значит и их базовая форма разная (так \"saucing\", если это глагол, имеет базовую форму \"sauce\"). Указание pos в аргументах решает эту проблему\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saucing : sauce\n"
     ]
    }
   ],
   "source": [
    "print(\"saucing :\", lemmatizer.lemmatize(\"saucing\", pos =\"v\")) # saucing : sauce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2. Удалите стоп-слова из описаний рецептов. Какую долю об общего количества слов составляли стоп-слова? Сравните топ-10 самых часто употребляемых слов до и после удаления стоп-слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(row):\n",
    "    return [el for el in row if not el in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля стоп-слов от общего количества слов: 0.456\n"
     ]
    }
   ],
   "source": [
    "preprocessed_descriptions['clean'] = preprocessed_descriptions.apply(\n",
    "         lambda row: remove_stopwords(row.words),\n",
    "         axis=1)\n",
    "clean_lst = sum(preprocessed_descriptions['clean'].str.len())\n",
    "raw_lst = sum(preprocessed_descriptions['words'].str.len())\n",
    "\n",
    "print(f'Доля стоп-слов от общего количества слов: {1 - (clean_lst/raw_lst):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'a', 'and', 'this', 'i', 'to', 'is', 'it', 'of', 'for']\n",
      "['recipe', 'make', 'time', 'use', 'great', 'like', 'easy', 'one', 'made', 'good']\n"
     ]
    }
   ],
   "source": [
    "words_after = nltk.FreqDist(np.hstack(preprocessed_descriptions['clean'].to_list())) \n",
    "words_before = nltk.FreqDist(np.hstack(preprocessed_descriptions['words'].to_list())) \n",
    "\n",
    "print([idx for idx,val in words_before.most_common(10)])\n",
    "print([idx for idx,val in words_after.most_common(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # для проверки - находим все стопслова\n",
    "# def stpwrds(row):\n",
    "#     return [el for el in row if el in stopwords.words('english')]\n",
    "\n",
    "# preprocessed_descriptions['stpwrds'] = preprocessed_descriptions.apply(\n",
    "#          lambda row: stpwrds(row.words),\n",
    "#          axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stpwrds_lst = sum(preprocessed_descriptions['stpwrds'].str.len())\n",
    "# print(f'Доля стоп-слов от общего количества слов: {stpwrds_lst/raw_lst:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Векторное представление текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Выберите случайным образом 5 рецептов из набора данных. Представьте описание каждого рецепта в виде числового вектора при помощи `TfidfVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 случайных рецептов\n",
    "preprocessed_descriptions_sample = preprocessed_descriptions.sample(n=5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>preprocessed_description</th>\n",
       "      <th>words</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10747</th>\n",
       "      <td>fantastic banana fruitcake</td>\n",
       "      <td>this cake is very moist it is the ultimate in ...</td>\n",
       "      <td>[this, cake, is, very, moist, it, is, the, ult...</td>\n",
       "      <td>[cake, moist, ultimate, fruit, cakes, think, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12573</th>\n",
       "      <td>greek orzo salad w  kalamata and feta</td>\n",
       "      <td>a great summer salad  serve room temperature o...</td>\n",
       "      <td>[a, great, summer, salad, serve, room, tempera...</td>\n",
       "      <td>[great, summer, salad, serve, room, temperatur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29676</th>\n",
       "      <td>yet   another tater tot casserole</td>\n",
       "      <td>i like to play with the below basic recipe  on...</td>\n",
       "      <td>[i, like, to, play, with, the, below, basic, r...</td>\n",
       "      <td>[like, play, basic, recipe, one, favorites, ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8856</th>\n",
       "      <td>crusty parmesan herb zucchini bites</td>\n",
       "      <td>aunt donna posted this on my facebook wall</td>\n",
       "      <td>[aunt, donna, posted, this, on, my, facebook, ...</td>\n",
       "      <td>[aunt, donna, posted, facebook, wall]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21098</th>\n",
       "      <td>pomegranate duck</td>\n",
       "      <td>i made a quail recipe similar to thisbut tonig...</td>\n",
       "      <td>[i, made, a, quail, recipe, similar, to, thisb...</td>\n",
       "      <td>[made, quail, recipe, similar, thisbut, tonigh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        name  \\\n",
       "10747             fantastic banana fruitcake   \n",
       "12573  greek orzo salad w  kalamata and feta   \n",
       "29676      yet   another tater tot casserole   \n",
       "8856     crusty parmesan herb zucchini bites   \n",
       "21098                       pomegranate duck   \n",
       "\n",
       "                                preprocessed_description  \\\n",
       "10747  this cake is very moist it is the ultimate in ...   \n",
       "12573  a great summer salad  serve room temperature o...   \n",
       "29676  i like to play with the below basic recipe  on...   \n",
       "8856          aunt donna posted this on my facebook wall   \n",
       "21098  i made a quail recipe similar to thisbut tonig...   \n",
       "\n",
       "                                                   words  \\\n",
       "10747  [this, cake, is, very, moist, it, is, the, ult...   \n",
       "12573  [a, great, summer, salad, serve, room, tempera...   \n",
       "29676  [i, like, to, play, with, the, below, basic, r...   \n",
       "8856   [aunt, donna, posted, this, on, my, facebook, ...   \n",
       "21098  [i, made, a, quail, recipe, similar, to, thisb...   \n",
       "\n",
       "                                                   clean  \n",
       "10747  [cake, moist, ultimate, fruit, cakes, think, p...  \n",
       "12573  [great, summer, salad, serve, room, temperatur...  \n",
       "29676  [like, play, basic, recipe, one, favorites, ad...  \n",
       "8856               [aunt, donna, posted, facebook, wall]  \n",
       "21098  [made, quail, recipe, similar, thisbut, tonigh...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_descriptions_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "matrix = vectorizer.fit_transform(preprocessed_descriptions_sample.preprocessed_description).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "вектор описания 1 => \n",
      "[0.         0.0984509  0.0984509  0.1969018  0.07942957 0.\n",
      " 0.         0.0984509  0.0984509  0.0984509  0.         0.\n",
      " 0.0984509  0.0984509  0.         0.0984509  0.         0.07942957\n",
      " 0.         0.2953527  0.1969018  0.0984509  0.         0.\n",
      " 0.         0.07942957 0.0984509  0.0984509  0.         0.\n",
      " 0.0984509  0.07942957 0.         0.         0.         0.0984509\n",
      " 0.         0.         0.         0.0984509  0.         0.0984509\n",
      " 0.2953527  0.         0.         0.         0.         0.\n",
      " 0.         0.         0.1969018  0.2382887  0.07942957 0.\n",
      " 0.0984509  0.0984509  0.0984509  0.         0.         0.0984509\n",
      " 0.         0.         0.         0.0984509  0.0984509  0.0984509\n",
      " 0.0984509  0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.0984509  0.         0.         0.\n",
      " 0.         0.1969018  0.         0.         0.         0.0984509\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.07942957 0.         0.\n",
      " 0.         0.         0.         0.0984509  0.         0.\n",
      " 0.         0.         0.         0.0984509  0.         0.0984509\n",
      " 0.0984509  0.         0.         0.         0.15885913 0.32966858\n",
      " 0.0984509  0.0984509  0.14073714 0.         0.07942957 0.06593372\n",
      " 0.         0.         0.         0.         0.0984509  0.0984509\n",
      " 0.         0.         0.1969018  0.         0.         0.1969018\n",
      " 0.0984509  0.06593372 0.        ]\n",
      "\n",
      "вектор описания 2 => \n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.21043974 0.         0.         0.         0.21043974 0.\n",
      " 0.         0.         0.         0.         0.         0.16978146\n",
      " 0.         0.         0.         0.         0.         0.21043974\n",
      " 0.21043974 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.21043974 0.\n",
      " 0.         0.         0.         0.21043974 0.         0.\n",
      " 0.         0.         0.         0.         0.16978146 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.21043974 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.33956292\n",
      " 0.         0.         0.         0.         0.21043974 0.\n",
      " 0.21043974 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.21043974 0.42087949\n",
      " 0.21043974 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.21043974 0.\n",
      " 0.         0.21043974 0.         0.21043974 0.         0.14093395\n",
      " 0.         0.         0.10027567 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n",
      "\n",
      "вектор описания 3 => \n",
      "[0.26661329 0.         0.         0.         0.21510192 0.\n",
      " 0.         0.         0.         0.         0.         0.0888711\n",
      " 0.         0.         0.0888711  0.         0.0888711  0.\n",
      " 0.0888711  0.         0.         0.         0.0888711  0.\n",
      " 0.         0.07170064 0.         0.         0.0888711  0.\n",
      " 0.         0.07170064 0.0888711  0.         0.0888711  0.\n",
      " 0.         0.0888711  0.0888711  0.         0.         0.\n",
      " 0.         0.17774219 0.0888711  0.         0.         0.0888711\n",
      " 0.0888711  0.0888711  0.         0.14340128 0.         0.0888711\n",
      " 0.         0.         0.         0.0888711  0.0888711  0.\n",
      " 0.         0.0888711  0.         0.         0.         0.\n",
      " 0.         0.0888711  0.0888711  0.07170064 0.0888711  0.0888711\n",
      " 0.35548438 0.0888711  0.0888711  0.         0.0888711  0.14340128\n",
      " 0.07170064 0.0888711  0.         0.0888711  0.         0.0888711\n",
      " 0.         0.         0.0888711  0.         0.0888711  0.\n",
      " 0.         0.07170064 0.0888711  0.         0.         0.\n",
      " 0.         0.         0.         0.07170064 0.26661329 0.0888711\n",
      " 0.0888711  0.0888711  0.0888711  0.         0.0888711  0.0888711\n",
      " 0.0888711  0.0888711  0.         0.         0.         0.\n",
      " 0.         0.         0.0888711  0.         0.07170064 0.29759004\n",
      " 0.         0.         0.04234755 0.         0.07170064 0.29759004\n",
      " 0.         0.0888711  0.0888711  0.0888711  0.         0.\n",
      " 0.07170064 0.0888711  0.         0.         0.         0.\n",
      " 0.         0.17855403 0.0888711 ]\n",
      "\n",
      "вектор описания 4 => \n",
      "[0.         0.         0.         0.         0.         0.38130259\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.38130259\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.38130259 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.30763253 0.         0.\n",
      " 0.         0.         0.         0.38130259 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.38130259 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.18169273 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.38130259 0.         0.\n",
      " 0.         0.         0.        ]\n",
      "\n",
      "вектор описания 5 => \n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.26653087 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.26653087 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.26653087 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.21503543 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.26653087 0.21503543 0.         0.26653087 0.         0.\n",
      " 0.         0.26653087 0.26653087 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.26653087 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.12700339 0.26653087 0.         0.17849883\n",
      " 0.26653087 0.         0.         0.         0.         0.\n",
      " 0.21503543 0.         0.         0.         0.26653087 0.\n",
      " 0.         0.17849883 0.        ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# мы получили матрицу, состоящую из 5 векторов (наши 5 описаний)\n",
    "for i in range(matrix.shape[0]):\n",
    "    print(f'вектор описания {i+1} => \\n{matrix[i]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Вычислите близость между каждой парой рецептов, используя косинусное расстояние (`scipy.spatial.distance.cosine`) Результаты оформите в виде таблицы `pd.DataFrame`. В качестве названий строк и столбцов используйте названия рецептов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_distance = pd.DataFrame(preprocessed_descriptions_sample.name)\n",
    "cosine_matrix = [[distance.cosine(matrix[i], matrix[j]) \n",
    "                      for j in range(len(cosine_distance.name))] \n",
    "                         for i in range(len(cosine_distance.name))]\n",
    "\n",
    "for idx, name in enumerate(cosine_distance.name):\n",
    "    cosine_distance[name] = cosine_matrix[idx]\n",
    "    \n",
    "cosine_distance.set_index('name', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_distance = pd.DataFrame(preprocessed_descriptions_sample.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_matrix = [[distance.cosine(matrix[i], matrix[j]) \n",
    "                      for j in range(len(cosine_distance.name))] \n",
    "                         for i in range(len(cosine_distance.name))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, name in enumerate(cosine_distance.name):\n",
    "    cosine_distance[name] = cosine_matrix[idx]\n",
    "    \n",
    "cosine_distance.set_index('name', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fantastic banana fruitcake</th>\n",
       "      <th>greek orzo salad w  kalamata and feta</th>\n",
       "      <th>yet   another tater tot casserole</th>\n",
       "      <th>crusty parmesan herb zucchini bites</th>\n",
       "      <th>pomegranate duck</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fantastic banana fruitcake</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.912455</td>\n",
       "      <td>0.779113</td>\n",
       "      <td>0.974429</td>\n",
       "      <td>0.958588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>greek orzo salad w  kalamata and feta</th>\n",
       "      <td>0.912455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.905119</td>\n",
       "      <td>0.981781</td>\n",
       "      <td>0.987265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yet   another tater tot casserole</th>\n",
       "      <td>0.779113</td>\n",
       "      <td>0.905119</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.970248</td>\n",
       "      <td>0.863376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crusty parmesan herb zucchini bites</th>\n",
       "      <td>0.974429</td>\n",
       "      <td>0.981781</td>\n",
       "      <td>0.970248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.976924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pomegranate duck</th>\n",
       "      <td>0.958588</td>\n",
       "      <td>0.987265</td>\n",
       "      <td>0.863376</td>\n",
       "      <td>0.976924</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       fantastic banana fruitcake  \\\n",
       "name                                                                \n",
       "fantastic banana fruitcake                               0.000000   \n",
       "greek orzo salad w  kalamata and feta                    0.912455   \n",
       "yet   another tater tot casserole                        0.779113   \n",
       "crusty parmesan herb zucchini bites                      0.974429   \n",
       "pomegranate duck                                         0.958588   \n",
       "\n",
       "                                       greek orzo salad w  kalamata and feta  \\\n",
       "name                                                                           \n",
       "fantastic banana fruitcake                                          0.912455   \n",
       "greek orzo salad w  kalamata and feta                               0.000000   \n",
       "yet   another tater tot casserole                                   0.905119   \n",
       "crusty parmesan herb zucchini bites                                 0.981781   \n",
       "pomegranate duck                                                    0.987265   \n",
       "\n",
       "                                       yet   another tater tot casserole  \\\n",
       "name                                                                       \n",
       "fantastic banana fruitcake                                      0.779113   \n",
       "greek orzo salad w  kalamata and feta                           0.905119   \n",
       "yet   another tater tot casserole                               0.000000   \n",
       "crusty parmesan herb zucchini bites                             0.970248   \n",
       "pomegranate duck                                                0.863376   \n",
       "\n",
       "                                       crusty parmesan herb zucchini bites  \\\n",
       "name                                                                         \n",
       "fantastic banana fruitcake                                        0.974429   \n",
       "greek orzo salad w  kalamata and feta                             0.981781   \n",
       "yet   another tater tot casserole                                 0.970248   \n",
       "crusty parmesan herb zucchini bites                               0.000000   \n",
       "pomegranate duck                                                  0.976924   \n",
       "\n",
       "                                       pomegranate duck  \n",
       "name                                                     \n",
       "fantastic banana fruitcake                     0.958588  \n",
       "greek orzo salad w  kalamata and feta          0.987265  \n",
       "yet   another tater tot casserole              0.863376  \n",
       "crusty parmesan herb zucchini bites            0.976924  \n",
       "pomegranate duck                               0.000000  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Какие рецепты являются наиболее похожими? Прокомментируйте результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7791128316984749"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# чем меньше полученный косинус, тем больше похожи две строки\n",
    "# но в нашей таблице строка сравнивается сама с собой, что нужно учесть (и убрать это полное совпадение, 0.0)\n",
    "highest_match = min([(cosine_distance[i].nsmallest(2)).max() for i in cosine_distance.columns])\n",
    "highest_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# значений 2, т.к. у нас совпадение и столбец-строка, и строка-столбец (зеркально относительно диагонали)\n",
    "i, j = np.where(cosine_distance.values == highest_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проверяем, что значения идентичны, а значит далее сможем обращаться к любому из них\n",
    "cosine_distance.columns[j[::-1]] == cosine_distance.columns[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this cake is very moist it is the ultimate in fruit cakes i think its the pureed banana along with the pineapple that makes this fruit cake so extra special make sure that the crushed pineapple is very well drained before adding to batter also this fruit cake can be succesfully baked in mini loaf pans just cut down baking time these cakes freeze well and also taste better when left until the following day'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_descriptions_sample.iloc[i[0]].preprocessed_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i like to play with the below basic recipe  one of my favorites is to add a package of drained and squeezed spinach and some garlic to the beef or some mushrooms  sometimes i add a little worcestershire to the soup too  occasionally ill add more soupi love that this is so versatile  experiment with different soups cheese vegetables next time im going to drizzle a bit of olive oil over the top of the tater tots and sprinkle with some herbs  perhaps garlic powder italian spices or crushed red pepper flakes'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_descriptions_sample.iloc[j[0]].preprocessed_description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "наши строки, по факту, похожи лишь на   (1 - 0.779 = 0.220)   22%, лишь малая часть слов совпадает"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
